<script lang="ts">
import {onMount} from "svelte";
import Tip from "$lib/Tip.svelte";
import Youtube from "$lib/Youtube.svelte";
import Docstring from "$lib/Docstring.svelte";
import CodeBlock from "$lib/CodeBlock.svelte";
import CodeBlockFw from "$lib/CodeBlockFw.svelte";
import DocNotebookDropdown from "$lib/DocNotebookDropdown.svelte";
import IconCopyLink from "$lib/IconCopyLink.svelte";
import FrameworkContent from "$lib/FrameworkContent.svelte";
import Markdown from "$lib/Markdown.svelte";
import Question from "$lib/Question.svelte";
import FrameworkSwitchCourse from "$lib/FrameworkSwitchCourse.svelte";
import InferenceApi from "$lib/InferenceApi.svelte";
import TokenizersLanguageContent from "$lib/TokenizersLanguageContent.svelte";
import ExampleCodeBlock from "$lib/ExampleCodeBlock.svelte";
import Added from "$lib/Added.svelte";
import Changed from "$lib/Changed.svelte";
import Deprecated from "$lib/Deprecated.svelte";
let fw: "pt" | "tf" = "pt";
onMount(() => {
    const urlParams = new URLSearchParams(window.location.search);
    fw = urlParams.get("fw") || "pt";
});
</script>
<svelte:head>
  <meta name="hf:doc:metadata" content={JSON.stringify(metadata)} >
</svelte:head>
# Introduction to Deep Reinforcement Learning [[introduction-to-deep-reinforcement-learning]]


TODO: ADD IMAGE THUMBNAIL


Welcome to the most fascinating topic in Artificial Intelligence:Â **Deep Reinforcement Learning.**

Deep RL is a type of Machine Learning where an agent learnsÂ **how to behave**Â in an environmentÂ **by performing actions**Â andÂ **seeing the results.**

So in this first chapter,Â **youâ€™ll learn the foundations of Deep Reinforcement Learning.** 

Then, you'll train your first two Deep Reinforcement Learning agents:

1. A Lunar Lander agent that will learn toÂ **land correctly on the Moon ğŸŒ•** 
2. A car that neads **to reach the top of the mountain â›°ï¸ **.


TODO: Add illustration MountainCar and MoonLanding

And finally youâ€™ll **upload it to the Hugging Face Hub ğŸ¤—, a free, open platform where people can share ML models, datasets and demos.**

TODO: ADD model card illustration

Hereâ€™s what youâ€™re going to accomplish at the end of this unit.

Itâ€™s essential **to master these elements**Â before diving into implementing Deep Reinforcement Learning agents. The goal of this chapter is to give you solid foundations.

So letâ€™s get started! ğŸš€









That was a lot of information, if we summarize:

- Reinforcement Learning is a computational approach of learning from action. We build an agent that learns from the environment **by interacting with it through trial and error** and receiving rewards (negative or positive) as feedback.
- The goal of any RL agent is to maximize its expected cumulative reward (also called expected return) because RL is based on the **reward hypothesis**, which is that **all goals can be described as the maximization of the expected cumulative reward.**
- The RL process is a loop that outputs a sequence of **state, action, reward and next state.**
- To calculate the expected cumulative reward (expected return), we discount the rewards: the rewards that come sooner (at the beginning of the game) **are more probable to happen since they are more predictable than the long term future reward.**
- To solve an RL problem, you want to **find an optimal policy**, the policy is the â€œbrainâ€ of your AI that will tell us **what action to take given a state.** The optimal one is the one who **gives you the actions that max the expected return.**
- There are two ways to find your optimal policy:
    1. By training your policy directly: **policy-based methods.**
    2. By training a value function that tells us the expected return the agent will get at each state and use this function to define our policy: **value-based methods.**
- Finally, we speak about Deep RL because we introduces **deep neural networks to estimate the action to take (policy-based) or to estimate the value of a state (value-based)** hence the name â€œdeep.â€

---

Now that you've studied the bases of Reinforcement Learning, youâ€™re ready to train your first lander agent toÂ **land correctly on the Moon ğŸŒ• and share it with the community through the Hub** ğŸ”¥

<figure class="image table text-center m-0 w-full">
<video
alt="LunarLander"
style="max-width: 70%; margin: auto;"
autoplay loop autobuffer muted playsinline
>
&amp;lt;source src="assets/63_deep_rl_intro/lunarlander.mp4" type="video/mp4">
</video>
</figure>

ADD To the notebook

Congrats on finishing this chapter!Â **That was the biggest one**, and there was a lot of information. And congrats on finishing the tutorial. Youâ€™ve just trained your first Deep RL agent and shared it on the Hub ğŸ¥³.

Thatâ€™sÂ **normal if you still feel confused**Â with all these elements.Â **This was the same for me and for all people who studied RL.**

Take time to really grasp the material before continuing. Itâ€™s important to master these elements and having a solid foundations before entering theÂ **fun part.**

We published additional readings in the syllabus if you want to go deeper ğŸ‘‰ [https://github.com/huggingface/deep-rl-class/blob/main/unit1/README.md](https://github.com/huggingface/deep-rl-class/blob/main/unit1/README.md)

Naturally, during the course,Â **weâ€™re going to use and explain these terms again**, but itâ€™s better to understand them before diving into the next chapters.

In the next chapter, [weâ€™re going to learn about Q-Learning and dive deeperÂ **into the value-based methods.**](https://huggingface.co/blog/deep-rl-q-part1)

And don't forget to share with your friends who want to learn ğŸ¤— !

Finally, we want **to improve and update the course iteratively with your feedback**. If you have some, please fill this form ğŸ‘‰ [https://forms.gle/3HgA7bEHwAmmLfwh9](https://forms.gle/3HgA7bEHwAmmLfwh9)

### Keep learning, stay awesome,